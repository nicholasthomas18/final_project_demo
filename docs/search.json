[
  {
    "objectID": "TechnicalReport.html",
    "href": "TechnicalReport.html",
    "title": "Technical Report",
    "section": "",
    "text": "This project delivers a Streamlit app and supporting Python functions to clean Ironman results data and generate practical performance insights. The app reports participation counts, continent breakdowns, top finishers by gender, which discipline correlates most with overall time, and benchmarks for a typical finisher and the slowest finisher. The main value is turning messy race result exports into consistent, interpretable summaries."
  },
  {
    "objectID": "TechnicalReport.html#executive-summary",
    "href": "TechnicalReport.html#executive-summary",
    "title": "Technical Report",
    "section": "",
    "text": "This project delivers a Streamlit app and supporting Python functions to clean Ironman results data and generate practical performance insights. The app reports participation counts, continent breakdowns, top finishers by gender, which discipline correlates most with overall time, and benchmarks for a typical finisher and the slowest finisher. The main value is turning messy race result exports into consistent, interpretable summaries."
  },
  {
    "objectID": "TechnicalReport.html#project-context",
    "href": "TechnicalReport.html#project-context",
    "title": "Technical Report",
    "section": "Project Context",
    "text": "Project Context\nIronman results files are often hard to analyze directly because times can appear in different formats and some rows represent DNFs or missing splits. The goal is to provide a reliable workflow that cleans triathlon data and then communicates insights interactively. Success is measured by correct parsing and filtering of results, clear summary outputs, and a simple upload-to-insight user experience in Streamlit."
  },
  {
    "objectID": "TechnicalReport.html#data-sources",
    "href": "TechnicalReport.html#data-sources",
    "title": "Technical Report",
    "section": "Data Sources",
    "text": "Data Sources\n\nPrimary dataset: St. George Ironman\nSupplementary data: Ironman Races\nData access notes: Data are provided by the user at runtime. No automated refresh or external API calls are used."
  },
  {
    "objectID": "TechnicalReport.html#methodology",
    "href": "TechnicalReport.html#methodology",
    "title": "Technical Report",
    "section": "Methodology",
    "text": "Methodology\n\nData acquisition:\n\nThe app reads the uploaded CSV using pandas (pd.read_csv(uploaded)), then copies the data into a working dataframe for transformations. Original data was complied from multiple sources.\n\nCleaning pipeline:\n\nTime parsing: parse_time_to_seconds() converts time strings into seconds for all TIME_COLS, handling mm:ss and hh:mm:ss and returning NaN on malformed values.\nTransitions: creates Transitions (sec) as T1 + T2 when available.\nGender normalization: normalize_gender() maps m/f variants to Male/Female and title-cases other values.\nFinisher logic: sets Finished to Overall Time (sec) present and greater than 0, and if a Finish column exists, additionally requires FIN.\n\nAnalysis workflow:\n\nParticipant summary: total participants, finishers, DNFs, and Male/Female counts.\nGeography: continent pie chart with small groups bundled into Other.\nPerformance tables: top 3 athletes per gender by overall time (finishers only), showing split and transitions breakdowns.\nDiscipline impact: correlation of each discipline with overall time, selecting the highest correlation as the “best predictor.”\nBenchmarks: typical finisher (closest to median overall time), slowest finisher profile, and slowest split times that still finished.\nExtra diagnostics: transitions vs overall scatter plot with correlation; age-group median times from Division patterns like M25-29 and F30-34.\n\nTooling:\n\nPackages: Python with pandas, numpy, regex, Streamlit, and matplotlib.\nReproducibility is supported and rerunnable on any dataset with the expected columns."
  },
  {
    "objectID": "TechnicalReport.html#results-diagnostics",
    "href": "TechnicalReport.html#results-diagnostics",
    "title": "Technical Report",
    "section": "Results & Diagnostics",
    "text": "Results & Diagnostics\nThe app provides summary statistics and figures to analyze triathlon times. Statistics include: - Number of Participants - Male / Female Ratio - Best Predictor of Overall Time - Preparation Insights\nExamples can be found here."
  },
  {
    "objectID": "TechnicalReport.html#discussion-next-steps",
    "href": "TechnicalReport.html#discussion-next-steps",
    "title": "Technical Report",
    "section": "Discussion & Next Steps",
    "text": "Discussion & Next Steps\nThis app works well for exploring results and getting benchmarks, but it assumes the CSV uses the expected column names and it does not fully check that all splits add up correctly.\nSome next steps: - Add a few quick tests to make sure time parsing and the “Finished” rule work every time - Improve the country to continent mapping, or let users upload their own mapping - Add simple checks (no negative times, no missing key splits, splits roughly match overall time)\nOverall, the project turns raw Ironman results into clean, trustworthy summaries that athletes can quickly use to understand performance and set realistic goals."
  },
  {
    "objectID": "Documentation.html",
    "href": "Documentation.html",
    "title": "Documentation",
    "section": "",
    "text": "Below is a reference guide for the functions used by the triathlon_project package. Import them via:\nfrom triathlon_project import (\n    clean_results_frame,\n    run_cleaning_pipeling,\n    summarize_participants,\n    top_finishers_by_gender,\n    discipline_correlations,\n    best_predictor,\n    run_analysis_pipeline,\n)\n\nclean_results_frame(frame:pd.DataFrame)\n    df = frame.copy()\n\n    _add_time_columns(df, TIME_COLUMNS)\n\n    if {\"Transition 1 Time (sec)\", \"Transition 2 Time (sec)\"}.issubset(df.columns):\n        df[\"Transitions (sec)\"] = (\n            df[\"Transition 1 Time (sec)\"] + df[\"Transition 2 Time (sec)\"]\n        )\n\n    if \"gender\" in df.columns:\n        df[\"gender_norm\"] = df[\"gender\"].apply(normalize_gender)\n\n    if \"Overall Time (sec)\" in df.columns:\n        df[\"Finished\"] = df[\"Overall Time (sec)\"].notna() & (\n            df[\"Overall Time (sec)\"] &gt; 0\n        )\n    else:\n        df[\"Finished\"] = False\n\n    if \"Finish\" in df.columns:\n        df[\"Finished\"] = df[\"Finished\"] & (\n            df[\"Finish\"].astype(str).str.upper().str.strip() == \"FIN\"\n        )\n\n    return df\nCreates a cleaned copy of raw triathlon results. It parses common time columns into numeric seconds, derives combined transition totals, normalizes gender labels, and adds a Finished boolean flag when possible. Use this function whenever you need consistent columns before analysis or visualization.\n\n\nrun_cleaning_pipeling(source: pd.DataFrame|str|Path|None=None)\ndef run_cleaning_pipeling(source: str | Path | pd.DataFrame | None = None) -&gt; pd.DataFrame:\n    print(\"Running cleaning pipeline...\")\n    if source is None:\n        return pd.DataFrame()\n\n    if isinstance(source, (str, Path)):\n        raw = pd.read_csv(source)\n    else:\n        raw = source\n\n    cleaned = clean_results_frame(raw)\n    print(f\"Parsed {len(cleaned):,} records.\")\n    return cleaned\nRuns the cleaning pipeline. If you pass a dataframe or path to a CSV file it returns the cleaned dataframe and prints simple progress messages. Calling it with no arguments just logs “Running cleaning pipeline…” to mirror the behaviour used in the starter tests/tutorial.\n\n\nsummarize_participants(df:pd.DataFrame)\ndef summarize_participants(df: pd.DataFrame) -&gt; Dict[str, int]:\n    total = len(df)\n    finishers = int(df.get(\"Finished\", pd.Series(dtype=int)).sum())\n    male = female = 0\n    if \"gender_norm\" in df.columns:\n        male = int((df[\"gender_norm\"] == \"Male\").sum())\n        female = int((df[\"gender_norm\"] == \"Female\").sum())\n    return {\n        \"participants\": total,\n        \"finishers\": finishers,\n        \"did_not_finish\": total - finishers,\n        \"male\": male,\n        \"female\": female,\n    }\nComputes summaries from a cleaned dataframe: total records, finisher counts, DNFs, and male/female totals (when gender_norm exists). Ideal for populating overview metric cards in a dashboard.\n\n\ntop_finishers_by_gender(fin_df:pd.DataFrame,\n\n\ngenders=(\"Female\",\"Male\"),limit=3)\ndef top_finishers_by_gender(\n    fin_df: pd.DataFrame, genders: Iterable[str] = (\"Female\", \"Male\"), limit: int = 3\n) -&gt; Dict[str, pd.DataFrame]:\n    results: Dict[str, pd.DataFrame] = {}\n    for gender in genders:\n        if \"gender_norm\" not in fin_df.columns:\n            results[gender] = fin_df.iloc[0:0]\n            continue\n        sub = fin_df[fin_df[\"gender_norm\"] == gender]\n        results[gender] = sub.nsmallest(limit, \"Overall Time (sec)\")\n    return results\nReturns the fastest limit finishers for each gender provided. Input should already be filtered to finishers (e.g., fin_df = df[df[\"Finished\"]]). Useful for spotlight tables showing podium athletes.\n\n\ndiscipline_correlations(fin_df:pd.DataFrame,min_samples:int=10)\ndef discipline_correlations(\n    fin_df: pd.DataFrame, min_samples: int = 10\n) -&gt; Dict[str, float]:\n    out: Dict[str, float] = {}\n    for label, column in DISCIPLINE_COLUMNS.items():\n        if column not in fin_df.columns or \"Overall Time (sec)\" not in fin_df.columns:\n            continue\n        valid = fin_df.dropna(subset=[column, \"Overall Time (sec)\"])\n        if len(valid) &lt;= min_samples:\n            continue\n        out[label] = valid[column].corr(valid[\"Overall Time (sec)\"])\n    return out\nComputes Pearson correlations between each split (Swim/Bike/Run/Transitions) and overall finishing time, skipping splits that lack data or sufficient samples. Helps identify which discipline best predicts overall performance.\n\n\nbest_predictor(fin_df:pd.DataFrame)\ndef best_predictor(fin_df: pd.DataFrame) -&gt; Tuple[str, float] | Tuple[None, None]:\n    cors = discipline_correlations(fin_df)\n    if not cors:\n        return None, None\n    best_col = max(cors, key=cors.get)\n    return best_col, cors[best_col]\nFunction that calls discipline_correlations and returns the discipline with the highest correlation to overall time. If no correlations are available it returns (None, None).\n\n\nrun_analysis_pipeline(source:pd.DataFrame|str|Path|None=None)\ndef run_analysis_pipeline(\n    source: pd.DataFrame | str | Path | None = None,\n) -&gt; Dict[str, object]:\n    print(\"Running analysis pipeline...\")\n    if source is None:\n        return {}\n\n    raw = _ensure_dataframe(source)\n    cleaned = clean_results_frame(raw)\n    if \"Finished\" in cleaned.columns:\n        finished_mask = cleaned[\"Finished\"].astype(bool)\n    else:\n        finished_mask = pd.Series(False, index=cleaned.index)\n    fin_df = cleaned[finished_mask]\n\n    result = {\n        \"participants\": summarize_participants(cleaned),\n        \"top_finishers\": top_finishers_by_gender(fin_df),\n        \"discipline_correlations\": discipline_correlations(fin_df),\n    }\n    print(\"Analysis pipeline finished.\")\n    return result\nThis function reads the raw data, cleans it with clean_results_frame, and returns a dictionary containing participant summaries, top finishers, and discipline correlations. When called without a source it simply prints a status message so scripted demos/tests keep passing."
  },
  {
    "objectID": "Tutorial.html",
    "href": "Tutorial.html",
    "title": "Triathlon Project",
    "section": "",
    "text": "The cleaning utilities turn messy CSV exports into consistent columns that downstream analysis can rely on.\n\nimport pandas as pd\nfrom triathlon_project import clean_results_frame\n\nraw = pd.DataFrame({\n    \"Name\": [\"Athlete A\", \"Athlete B\"],\n    \"gender\": [\"F\", \"M\"],\n    \"Overall Time\": [\"10:15:30\", \"11:05:12\"],\n    \"Swim Time\": [\"01:05:00\", \"01:15:40\"],\n    \"Bike Time\": [\"05:15:00\", \"05:40:30\"],\n    \"Run Time\": [\"03:45:30\", \"04:00:00\"],\n    \"Transition 1 Time\": [\"00:04:00\", \"00:05:30\"],\n    \"Transition 2 Time\": [\"00:05:00\", \"00:04:30\"],\n})\n\ncleaned = clean_results_frame(raw)\ncleaned[[\n    \"Name\",\n    \"gender_norm\",\n    \"Overall Time (sec)\",\n    \"Transitions (sec)\",\n    \"Finished\"\n]]\n\n\n\n\n\n\n\n\nName\ngender_norm\nOverall Time (sec)\nTransitions (sec)\nFinished\n\n\n\n\n0\nAthlete A\nFemale\n36930\n540\nTrue\n\n\n1\nAthlete B\nMale\n39912\n600\nTrue"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "The Triathlon Python Package",
    "section": "",
    "text": "Athletes transitioning from swim to bike to run during a triathlon\n\n\nTriathlon results are packed with information about performance, but the raw data is often inconsistent and hard to analyze. This project is a Python package that collects, cleans, and analyzes triathlon split times to produce clear metrics and visuals across swim, bike, and run, with an accompanying Streamlit app for interactive exploration.\nDocumentation here.\nGet started here.\nReview the technical report."
  },
  {
    "objectID": "Tutorial.html#load-and-clean-raw-results",
    "href": "Tutorial.html#load-and-clean-raw-results",
    "title": "Triathlon Project",
    "section": "",
    "text": "The cleaning utilities turn messy CSV exports into consistent columns that downstream analysis can rely on.\n\nimport pandas as pd\nfrom triathlon_project import clean_results_frame\n\nraw = pd.DataFrame({\n    \"Name\": [\"Athlete A\", \"Athlete B\"],\n    \"gender\": [\"F\", \"M\"],\n    \"Overall Time\": [\"10:15:30\", \"11:05:12\"],\n    \"Swim Time\": [\"01:05:00\", \"01:15:40\"],\n    \"Bike Time\": [\"05:15:00\", \"05:40:30\"],\n    \"Run Time\": [\"03:45:30\", \"04:00:00\"],\n    \"Transition 1 Time\": [\"00:04:00\", \"00:05:30\"],\n    \"Transition 2 Time\": [\"00:05:00\", \"00:04:30\"],\n})\n\ncleaned = clean_results_frame(raw)\ncleaned[[\n    \"Name\",\n    \"gender_norm\",\n    \"Overall Time (sec)\",\n    \"Transitions (sec)\",\n    \"Finished\"\n]]\n\n\n\n\n\n\n\n\nName\ngender_norm\nOverall Time (sec)\nTransitions (sec)\nFinished\n\n\n\n\n0\nAthlete A\nFemale\n36930\n540\nTrue\n\n\n1\nAthlete B\nMale\n39912\n600\nTrue"
  },
  {
    "objectID": "Tutorial.html#summarize-metrics",
    "href": "Tutorial.html#summarize-metrics",
    "title": "Triathlon Project",
    "section": "2. Summarize metrics",
    "text": "2. Summarize metrics\nOnce you have a cleaned dataframe you can compute participant metrics or highlight top performers.\n\nfrom triathlon_project import summarize_participants, top_finishers_by_gender\n\nsummary = summarize_participants(cleaned)\nsummary\n\n{'participants': 2,\n 'finishers': 2,\n 'did_not_finish': 0,\n 'male': 1,\n 'female': 1}\n\n\n\ntop = top_finishers_by_gender(cleaned[cleaned[\"Finished\"]])\ntop[\"Female\"][[\"Name\", \"Overall Time (sec)\"]]\n\n\n\n\n\n\n\n\nName\nOverall Time (sec)\n\n\n\n\n0\nAthlete A\n36930"
  },
  {
    "objectID": "Tutorial.html#run-the-full-pipeline",
    "href": "Tutorial.html#run-the-full-pipeline",
    "title": "Triathlon Project",
    "section": "3. Run the full pipeline",
    "text": "3. Run the full pipeline\nThe high-level pipeline accepts either a dataframe or a CSV path and returns a dictionary with the common insights used in the Streamlit demo.\n\nfrom triathlon_project import run_analysis_pipeline\n\nresults = run_analysis_pipeline(cleaned)\nresults.keys()\n\nRunning analysis pipeline...\nAnalysis pipeline finished.\n\n\ndict_keys(['participants', 'top_finishers', 'discipline_correlations'])\n\n\nAnd that’s it! Upload your race results in a CSV, let the package clean and analyze, and reuse the outputs in notebooks, scripts, or dashboards."
  }
]